
Best Saved

































Epoch #1: 20001it [01:07, 296.51it/s, env_step=20000, len=0, n/ep=0, n/st=400, pursuer_0/loss=0.113, pursuer_1/loss=0.040, pursuer_2/loss=0.094, pursuer_3/loss=0.121, pursuer_4/loss=0.061, pursuer_5/loss=0.085, pursuer_6/loss=0.155, pursuer_7/loss=0.122, rew=0.00]
Best Saved
Epoch #1: test_reward: -34.336625 Â± 14.109820, best_reward: -34.336625 Â± 14.109820 in #1
































Epoch #2: 20001it [01:04, 309.16it/s, env_step=40000, len=4000, n/ep=10, n/st=400, pursuer_0/loss=0.158, pursuer_1/loss=0.130, pursuer_2/loss=0.168, pursuer_3/loss=0.256, pursuer_4/loss=0.182, pursuer_5/loss=0.220, pursuer_6/loss=0.212, pursuer_7/loss=0.229, rew=-29.21]
Best Saved
Epoch #2: test_reward: -27.004313 Â± 15.174809, best_reward: -27.004313 Â± 15.174809 in #2
































Epoch #3: 20001it [01:04, 310.89it/s, env_step=60000, len=4000, n/ep=0, n/st=400, pursuer_0/loss=0.222, pursuer_1/loss=0.303, pursuer_2/loss=0.241, pursuer_3/loss=0.255, pursuer_4/loss=0.338, pursuer_5/loss=0.392, pursuer_6/loss=0.457, pursuer_7/loss=0.436, rew=-29.21]
Best Saved
Epoch #3: test_reward: -12.202813 Â± 15.568487, best_reward: -12.202813 Â± 15.568487 in #3































Epoch #4: 20001it [01:02, 320.75it/s, env_step=80000, len=4000, n/ep=10, n/st=400, pursuer_0/loss=0.247, pursuer_1/loss=0.257, pursuer_2/loss=0.255, pursuer_3/loss=0.282, pursuer_4/loss=0.326, pursuer_5/loss=0.431, pursuer_6/loss=0.354, pursuer_7/loss=0.353, rew=-10.22]
Epoch #5:   0%|          | 0/20000 [00:00<?, ?it/s]
Best Saved

































Epoch #5: 20001it [01:05, 303.85it/s, env_step=100000, len=4000, n/ep=0, n/st=400, pursuer_0/loss=0.357, pursuer_1/loss=0.306, pursuer_2/loss=0.419, pursuer_3/loss=0.365, pursuer_4/loss=0.422, pursuer_5/loss=0.492, pursuer_6/loss=0.493, pursuer_7/loss=0.484, rew=-10.22]
Epoch #6:   2%|2         | 400/20000 [00:00<00:26, 728.78it/s]
Best Saved






























Epoch #6: 20001it [01:00, 332.67it/s, env_step=120000, len=4000, n/ep=10, n/st=400, pursuer_0/loss=0.325, pursuer_1/loss=0.332, pursuer_2/loss=0.303, pursuer_3/loss=0.396, pursuer_4/loss=0.459, pursuer_5/loss=0.486, pursuer_6/loss=0.508, pursuer_7/loss=0.581, rew=3.88]
Epoch #6: test_reward: -8.716813 Â± 14.791763, best_reward: 4.098562 Â± 16.880829 in #5
































Epoch #7: 20001it [01:05, 305.03it/s, env_step=140000, len=4000, n/ep=0, n/st=400, pursuer_0/loss=0.373, pursuer_1/loss=0.442, pursuer_2/loss=0.441, pursuer_3/loss=0.429, pursuer_4/loss=0.420, pursuer_5/loss=0.516, pursuer_6/loss=0.540, pursuer_7/loss=0.610, rew=3.88]
Best Saved
Epoch #7: test_reward: 10.763875 Â± 19.017483, best_reward: 10.763875 Â± 19.017483 in #7





























Epoch #8: 20001it [00:59, 335.08it/s, env_step=160000, len=4000, n/ep=10, n/st=400, pursuer_0/loss=0.430, pursuer_1/loss=0.523, pursuer_2/loss=0.534, pursuer_3/loss=0.491, pursuer_4/loss=0.471, pursuer_5/loss=0.576, pursuer_6/loss=0.571, pursuer_7/loss=0.634, rew=10.78]
Epoch #9:   2%|2         | 400/20000 [00:01<00:32, 609.00it/s, env_step=160400, len=4000, n/ep=0, n/st=400, pursuer_0/loss=0.428, pursuer_1/loss=0.521, pursuer_2/loss=0.522, pursuer_3/loss=0.493, pursuer_4/loss=0.482, pursuer_5/loss=0.586, pursuer_6/loss=0.564, pursuer_7/loss=0.619, rew=10.78]
































Epoch #9: 20001it [01:04, 309.18it/s, env_step=180000, len=4000, n/ep=0, n/st=400, pursuer_0/loss=0.484, pursuer_1/loss=0.549, pursuer_2/loss=0.596, pursuer_3/loss=0.489, pursuer_4/loss=0.535, pursuer_5/loss=0.603, pursuer_6/loss=0.619, pursuer_7/loss=0.655, rew=10.78]
Epoch #10:   2%|2         | 400/20000 [00:00<00:28, 697.39it/s]






























Epoch #10: 20001it [01:00, 332.88it/s, env_step=200000, len=4000, n/ep=9, n/st=400, pursuer_0/loss=0.463, pursuer_1/loss=0.399, pursuer_2/loss=0.553, pursuer_3/loss=0.518, pursuer_4/loss=0.566, pursuer_5/loss=0.651, pursuer_6/loss=0.651, pursuer_7/loss=0.607, rew=6.81]
Epoch #11:   0%|          | 0/20000 [00:00<?, ?it/s]
































Epoch #11: 20001it [01:03, 315.05it/s, env_step=220000, len=4000, n/ep=0, n/st=400, pursuer_0/loss=0.514, pursuer_1/loss=0.659, pursuer_2/loss=0.538, pursuer_3/loss=0.526, pursuer_4/loss=0.599, pursuer_5/loss=0.684, pursuer_6/loss=0.699, pursuer_7/loss=0.795, rew=6.81]
Epoch #12:   2%|2         | 400/20000 [00:00<00:25, 777.31it/s]






























Epoch #12: 20001it [01:00, 330.08it/s, env_step=240000, len=4000, n/ep=6, n/st=400, pursuer_0/loss=0.550, pursuer_1/loss=0.628, pursuer_2/loss=0.562, pursuer_3/loss=0.638, pursuer_4/loss=0.580, pursuer_5/loss=0.797, pursuer_6/loss=0.639, pursuer_7/loss=0.758, rew=3.41]
Epoch #12: test_reward: -14.466250 Â± 17.099528, best_reward: 10.763875 Â± 19.017483 in #7































Epoch #13: 20001it [01:01, 322.84it/s, env_step=260000, len=4000, n/ep=0, n/st=400, pursuer_0/loss=0.552, pursuer_1/loss=0.604, pursuer_2/loss=0.714, pursuer_3/loss=0.652, pursuer_4/loss=0.637, pursuer_5/loss=0.785, pursuer_6/loss=0.695, pursuer_7/loss=0.654, rew=3.41]
Epoch #13: test_reward: -5.658313 Â± 20.572588, best_reward: 10.763875 Â± 19.017483 in #7































Epoch #14: 20001it [01:00, 328.63it/s, env_step=280000, len=4000, n/ep=3, n/st=400, pursuer_0/loss=0.622, pursuer_1/loss=0.681, pursuer_2/loss=0.690, pursuer_3/loss=0.731, pursuer_4/loss=0.736, pursuer_5/loss=0.852, pursuer_6/loss=0.764, pursuer_7/loss=0.814, rew=-5.81]
Epoch #14: test_reward: -0.202938 Â± 22.292569, best_reward: 10.763875 Â± 19.017483 in #7






























Epoch #15: 20001it [01:00, 329.28it/s, env_step=300000, len=2976, n/ep=0, n/st=400, pursuer_0/loss=0.608, pursuer_1/loss=0.767, pursuer_2/loss=0.745, pursuer_3/loss=0.770, pursuer_4/loss=0.728, pursuer_5/loss=0.926, pursuer_6/loss=0.913, pursuer_7/loss=0.891, rew=-10.84]
Epoch #15: test_reward: -2.202813 Â± 24.320378, best_reward: 10.763875 Â± 19.017483 in #7






























Epoch #16: 20001it [01:00, 331.11it/s, env_step=320000, len=4000, n/ep=1, n/st=400, pursuer_0/loss=0.661, pursuer_1/loss=0.695, pursuer_2/loss=0.738, pursuer_3/loss=0.803, pursuer_4/loss=0.779, pursuer_5/loss=0.898, pursuer_6/loss=0.845, pursuer_7/loss=0.927, rew=30.58]
Epoch #17:   0%|          | 0/20000 [00:00<?, ?it/s]





























Epoch #17: 20001it [00:57, 346.89it/s, env_step=340000, len=4000, n/ep=0, n/st=400, pursuer_0/loss=0.731, pursuer_1/loss=0.689, pursuer_2/loss=0.904, pursuer_3/loss=0.767, pursuer_4/loss=0.763, pursuer_5/loss=0.861, pursuer_6/loss=0.860, pursuer_7/loss=0.923, rew=15.92]
Epoch #17: test_reward: 0.857437 Â± 15.934526, best_reward: 10.763875 Â± 19.017483 in #7
































Epoch #18: 20001it [01:02, 318.01it/s, env_step=360000, len=4000, n/ep=0, n/st=400, pursuer_0/loss=0.612, pursuer_1/loss=0.654, pursuer_2/loss=0.665, pursuer_3/loss=0.850, pursuer_4/loss=0.818, pursuer_5/loss=0.919, pursuer_6/loss=0.806, pursuer_7/loss=0.872, rew=31.22]
Epoch #19:   0%|          | 0/20000 [00:00<?, ?it/s]
Best Saved



















Epoch #19:  62%|######2   | 12400/20000 [00:36<00:22, 337.29it/s, env_step=372000, len=2320, n/ep=0, n/st=400, pursuer_0/loss=0.787, pursuer_1/loss=0.732, pursuer_2/loss=0.836, pursuer_3/loss=0.821, pursuer_4/loss=0.822, pursuer_5/loss=0.982, pursuer_6/loss=0.948, pursuer_7/loss=1.006, rew=47.50]
{
    "discount_factor": 0.98,
    "estimation_step": 20,
    "target_update_freq": 1000,
    "optminizer": "Adam",
    "lr": 0.00016,
    "max_epoch": 500,
    "step_per_epoch": 20000,
    "step_per_collect": 400,
    "episode_per_test": 20,
    "batch_size": 256,
    "update_per_step": 0.02,
    "tn_eps_max": 0.1,
    "ts_eps_max": 0.0,
    "max_cycles": 500,
    "x_size": 16,
    "y_size": 16,
    "shared_reward": false,
    "n_evaders": 30,
    "n_pursuers": 8,
    "obs_range": 7,
    "n_catch": 2,
    "freeze_evaders": false,
    "tag_reward": 0.01,
    "catch_reward": 5.0,
    "urgency_reward": -0.1,
    "surround": true,
    "constraint_window": 1.0
}
Loaded-> dqn_SISL\policy_CNN_SISL_SISL_NOV12_Emb128.pth
Buffer Warming Up
d:\Python310\lib\site-packages\torch\nn\init.py:412: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
.
Buffer Lenght:  9.502
Epoch #1:   0%|          | 0/20000 [00:00<?, ?it/s]






























Epoch #1: 20001it [01:00, 329.08it/s, env_step=20000, len=1992, n/ep=1, n/st=400, pursuer_0/loss=0.894, pursuer_1/loss=1.114, pursuer_2/loss=1.087, pursuer_3/loss=1.151, pursuer_4/loss=1.036, pursuer_5/loss=1.094, pursuer_6/loss=1.221, pursuer_7/loss=1.201, rew=30.73]
Best Saved
Epoch #1: test_reward: 8.425437 Â± 26.027905, best_reward: 8.425437 Â± 26.027905 in #1


























Epoch #2: 20001it [00:52, 381.04it/s, env_step=40000, len=4000, n/ep=8, n/st=400, pursuer_0/loss=0.794, pursuer_1/loss=0.977, pursuer_2/loss=0.974, pursuer_3/loss=0.994, pursuer_4/loss=1.012, pursuer_5/loss=0.894, pursuer_6/loss=1.018, pursuer_7/loss=1.000, rew=7.76]
Epoch #3:   0%|          | 0/20000 [00:00<?, ?it/s]




























Epoch #3: 20001it [00:54, 363.95it/s, env_step=60000, len=4000, n/ep=0, n/st=400, pursuer_0/loss=0.761, pursuer_1/loss=0.816, pursuer_2/loss=0.913, pursuer_3/loss=1.011, pursuer_4/loss=0.887, pursuer_5/loss=0.898, pursuer_6/loss=0.928, pursuer_7/loss=1.067, rew=7.76]
Epoch #4:   2%|2         | 400/20000 [00:00<00:19, 989.32it/s]
Best Saved



























Epoch #4: 20001it [00:53, 373.04it/s, env_step=80000, len=4000, n/ep=5, n/st=400, pursuer_0/loss=0.757, pursuer_1/loss=0.819, pursuer_2/loss=0.773, pursuer_3/loss=1.040, pursuer_4/loss=0.831, pursuer_5/loss=0.819, pursuer_6/loss=0.914, pursuer_7/loss=0.922, rew=1.19]
Epoch #5:   0%|          | 0/20000 [00:00<?, ?it/s]
Best Saved






































Epoch #5: 20001it [01:14, 266.98it/s, env_step=100000, len=1728, n/ep=0, n/st=400, pursuer_0/loss=0.785, pursuer_1/loss=0.762, pursuer_2/loss=0.884, pursuer_3/loss=0.948, pursuer_4/loss=0.933, pursuer_5/loss=0.925, pursuer_6/loss=0.899, pursuer_7/loss=1.028, rew=29.06]
Epoch #6:   2%|2         | 400/20000 [00:00<00:28, 691.27it/s]













































Epoch #6: 20001it [01:30, 220.46it/s, env_step=120000, len=4000, n/ep=3, n/st=400, pursuer_0/loss=0.810, pursuer_1/loss=0.912, pursuer_2/loss=1.016, pursuer_3/loss=1.055, pursuer_4/loss=1.027, pursuer_5/loss=0.979, pursuer_6/loss=1.043, pursuer_7/loss=1.044, rew=12.64]
Best Saved
Epoch #6: test_reward: 28.213875 Â± 32.505893, best_reward: 28.213875 Â± 32.505893 in #6










































Epoch #7: 20001it [01:26, 232.37it/s, env_step=140000, len=4000, n/ep=0, n/st=400, pursuer_0/loss=0.891, pursuer_1/loss=0.848, pursuer_2/loss=0.874, pursuer_3/loss=1.067, pursuer_4/loss=0.902, pursuer_5/loss=0.901, pursuer_6/loss=1.081, pursuer_7/loss=0.947, rew=-4.44]
Epoch #8:   0%|          | 0/20000 [00:00<?, ?it/s]











































Epoch #8: 20001it [01:26, 231.39it/s, env_step=160000, len=4000, n/ep=1, n/st=400, pursuer_0/loss=0.808, pursuer_1/loss=0.821, pursuer_2/loss=0.902, pursuer_3/loss=0.897, pursuer_4/loss=0.902, pursuer_5/loss=0.931, pursuer_6/loss=0.931, pursuer_7/loss=0.939, rew=0.36]
Epoch #9:   0%|          | 0/20000 [00:00<?, ?it/s]










































Epoch #9: 20001it [01:24, 237.33it/s, env_step=180000, len=4000, n/ep=0, n/st=400, pursuer_0/loss=0.803, pursuer_1/loss=0.926, pursuer_2/loss=1.054, pursuer_3/loss=0.997, pursuer_4/loss=0.949, pursuer_5/loss=1.020, pursuer_6/loss=1.026, pursuer_7/loss=0.967, rew=-23.28]
Epoch #10:   2%|2         | 400/20000 [00:00<00:32, 607.05it/s]

































Epoch #10: 20001it [01:05, 304.18it/s, env_step=200000, len=4000, n/ep=1, n/st=400, pursuer_0/loss=0.805, pursuer_1/loss=0.891, pursuer_2/loss=0.943, pursuer_3/loss=0.888, pursuer_4/loss=0.784, pursuer_5/loss=0.864, pursuer_6/loss=0.951, pursuer_7/loss=0.852, rew=35.60]
Epoch #11:   2%|2         | 400/20000 [00:00<00:28, 699.96it/s]































Epoch #11: 20001it [01:01, 323.69it/s, env_step=220000, len=2184, n/ep=0, n/st=400, pursuer_0/loss=0.801, pursuer_1/loss=0.899, pursuer_2/loss=0.833, pursuer_3/loss=0.925, pursuer_4/loss=0.936, pursuer_5/loss=0.967, pursuer_6/loss=0.976, pursuer_7/loss=0.967, rew=78.68]
Epoch #11: test_reward: 22.828437 Â± 30.848377, best_reward: 28.213875 Â± 32.505893 in #6



































Epoch #12: 20001it [01:11, 281.01it/s, env_step=240000, len=4000, n/ep=0, n/st=400, pursuer_0/loss=0.792, pursuer_1/loss=0.869, pursuer_2/loss=0.894, pursuer_3/loss=0.979, pursuer_4/loss=0.925, pursuer_5/loss=0.863, pursuer_6/loss=0.975, pursuer_7/loss=0.907, rew=-19.21]
Epoch #12: test_reward: 9.929375 Â± 28.373489, best_reward: 28.213875 Â± 32.505893 in #6





































Epoch #13: 20001it [01:14, 267.90it/s, env_step=260000, len=3944, n/ep=0, n/st=400, pursuer_0/loss=0.834, pursuer_1/loss=1.073, pursuer_2/loss=0.925, pursuer_3/loss=1.008, pursuer_4/loss=0.870, pursuer_5/loss=0.865, pursuer_6/loss=0.863, pursuer_7/loss=1.157, rew=6.93]
Epoch #13: test_reward: 27.587750 Â± 27.858948, best_reward: 28.213875 Â± 32.505893 in #6


































Epoch #14: 20001it [01:08, 293.08it/s, env_step=280000, len=3000, n/ep=1, n/st=400, pursuer_0/loss=0.829, pursuer_1/loss=0.811, pursuer_2/loss=0.906, pursuer_3/loss=0.900, pursuer_4/loss=0.810, pursuer_5/loss=0.890, pursuer_6/loss=1.023, pursuer_7/loss=0.891, rew=33.68]
Epoch #15:   0%|          | 0/20000 [00:00<?, ?it/s]


































Epoch #15: 20001it [01:07, 296.82it/s, env_step=300000, len=1624, n/ep=0, n/st=400, pursuer_0/loss=0.847, pursuer_1/loss=1.099, pursuer_2/loss=0.874, pursuer_3/loss=1.052, pursuer_4/loss=0.921, pursuer_5/loss=1.004, pursuer_6/loss=1.029, pursuer_7/loss=1.122, rew=45.41]
Epoch #15: test_reward: 14.587312 Â± 24.363245, best_reward: 28.213875 Â± 32.505893 in #6


































Epoch #16: 20001it [01:07, 296.56it/s, env_step=320000, len=4000, n/ep=0, n/st=400, pursuer_0/loss=0.896, pursuer_1/loss=0.836, pursuer_2/loss=0.914, pursuer_3/loss=0.943, pursuer_4/loss=1.029, pursuer_5/loss=0.980, pursuer_6/loss=1.033, pursuer_7/loss=0.916, rew=0.83]
Epoch #17:   2%|2         | 400/20000 [00:00<00:25, 777.51it/s]

































Epoch #17: 20001it [01:05, 306.46it/s, env_step=340000, len=2432, n/ep=0, n/st=400, pursuer_0/loss=0.855, pursuer_1/loss=0.891, pursuer_2/loss=0.853, pursuer_3/loss=0.952, pursuer_4/loss=1.017, pursuer_5/loss=0.936, pursuer_6/loss=0.943, pursuer_7/loss=0.890, rew=35.69]
Epoch #18:   2%|2         | 400/20000 [00:00<00:23, 840.65it/s]


































Epoch #18: 20001it [01:08, 292.27it/s, env_step=360000, len=4000, n/ep=0, n/st=400, pursuer_0/loss=0.884, pursuer_1/loss=0.837, pursuer_2/loss=0.924, pursuer_3/loss=0.963, pursuer_4/loss=0.852, pursuer_5/loss=0.983, pursuer_6/loss=0.997, pursuer_7/loss=1.009, rew=35.59]
Epoch #19:   0%|          | 0/20000 [00:00<?, ?it/s]


































Epoch #19: 20001it [01:07, 294.72it/s, env_step=380000, len=3768, n/ep=1, n/st=400, pursuer_0/loss=0.812, pursuer_1/loss=0.812, pursuer_2/loss=0.864, pursuer_3/loss=0.916, pursuer_4/loss=0.893, pursuer_5/loss=1.041, pursuer_6/loss=0.911, pursuer_7/loss=0.998, rew=13.51]
Epoch #19: test_reward: 27.115687 Â± 29.418026, best_reward: 28.213875 Â± 32.505893 in #6


































Epoch #20: 20001it [01:09, 289.18it/s, env_step=400000, len=4000, n/ep=0, n/st=400, pursuer_0/loss=0.770, pursuer_1/loss=0.872, pursuer_2/loss=0.931, pursuer_3/loss=0.837, pursuer_4/loss=0.902, pursuer_5/loss=0.921, pursuer_6/loss=0.986, pursuer_7/loss=0.957, rew=-4.35]
Epoch #21:   0%|          | 0/20000 [00:00<?, ?it/s]



































Epoch #21: 20001it [01:10, 283.54it/s, env_step=420000, len=4000, n/ep=1, n/st=400, pursuer_0/loss=0.738, pursuer_1/loss=0.798, pursuer_2/loss=0.890, pursuer_3/loss=0.993, pursuer_4/loss=0.890, pursuer_5/loss=1.050, pursuer_6/loss=0.967, pursuer_7/loss=1.037, rew=41.29]
Epoch #22:   2%|2         | 400/20000 [00:00<00:26, 748.43it/s]

































Epoch #22: 20001it [01:07, 295.36it/s, env_step=440000, len=2760, n/ep=0, n/st=400, pursuer_0/loss=0.908, pursuer_1/loss=0.860, pursuer_2/loss=0.830, pursuer_3/loss=0.959, pursuer_4/loss=0.964, pursuer_5/loss=0.846, pursuer_6/loss=0.952, pursuer_7/loss=0.993, rew=46.55]
Epoch #23:   0%|          | 0/20000 [00:00<?, ?it/s]


































Epoch #23: 20001it [01:07, 296.43it/s, env_step=460000, len=4000, n/ep=0, n/st=400, pursuer_0/loss=0.838, pursuer_1/loss=0.921, pursuer_2/loss=1.097, pursuer_3/loss=1.126, pursuer_4/loss=1.014, pursuer_5/loss=1.117, pursuer_6/loss=1.038, pursuer_7/loss=1.073, rew=75.99]
Epoch #23: test_reward: 14.737937 Â± 24.701227, best_reward: 28.213875 Â± 32.505893 in #6
































Epoch #24: 20001it [01:05, 305.60it/s, env_step=480000, len=3512, n/ep=0, n/st=400, pursuer_0/loss=0.912, pursuer_1/loss=1.013, pursuer_2/loss=0.893, pursuer_3/loss=1.048, pursuer_4/loss=0.947, pursuer_5/loss=1.035, pursuer_6/loss=0.926, pursuer_7/loss=1.118, rew=21.93]
Best Saved
Epoch #24: test_reward: 31.509187 Â± 21.994771, best_reward: 31.509187 Â± 21.994771 in #24
































Epoch #25: 20001it [01:05, 303.24it/s, env_step=500000, len=2892, n/ep=0, n/st=400, pursuer_0/loss=0.958, pursuer_1/loss=1.020, pursuer_2/loss=1.080, pursuer_3/loss=1.118, pursuer_4/loss=1.008, pursuer_5/loss=1.080, pursuer_6/loss=0.968, pursuer_7/loss=1.113, rew=54.87]
Epoch #26:   2%|2         | 400/20000 [00:00<00:24, 787.52it/s]

































Epoch #26: 20001it [01:05, 306.87it/s, env_step=520000, len=1816, n/ep=0, n/st=400, pursuer_0/loss=1.077, pursuer_1/loss=1.174, pursuer_2/loss=1.004, pursuer_3/loss=1.202, pursuer_4/loss=1.186, pursuer_5/loss=1.230, pursuer_6/loss=1.080, pursuer_7/loss=1.336, rew=7.88]
Epoch #27:   2%|2         | 400/20000 [00:00<00:27, 712.61it/s]

































Epoch #27: 20001it [01:06, 302.90it/s, env_step=540000, len=4000, n/ep=0, n/st=400, pursuer_0/loss=0.905, pursuer_1/loss=1.023, pursuer_2/loss=0.981, pursuer_3/loss=1.123, pursuer_4/loss=0.934, pursuer_5/loss=0.965, pursuer_6/loss=1.005, pursuer_7/loss=1.131, rew=23.23]
Epoch #28:   2%|2         | 400/20000 [00:00<00:24, 791.69it/s]

































Epoch #28: 20001it [01:06, 298.95it/s, env_step=560000, len=1312, n/ep=0, n/st=400, pursuer_0/loss=0.976, pursuer_1/loss=1.157, pursuer_2/loss=1.184, pursuer_3/loss=1.157, pursuer_4/loss=1.092, pursuer_5/loss=1.160, pursuer_6/loss=1.146, pursuer_7/loss=1.238, rew=79.79]
Epoch #29:   2%|2         | 400/20000 [00:01<00:24, 813.41it/s, env_step=560400, len=1312, n/ep=0, n/st=400, pursuer_0/loss=0.943, pursuer_1/loss=1.151, pursuer_2/loss=1.171, pursuer_3/loss=1.182, pursuer_4/loss=1.110, pursuer_5/loss=1.208, pursuer_6/loss=1.175, pursuer_7/loss=1.224, rew=79.79]
































Epoch #29: 20001it [01:05, 306.67it/s, env_step=580000, len=1288, n/ep=0, n/st=400, pursuer_0/loss=0.999, pursuer_1/loss=1.064, pursuer_2/loss=1.044, pursuer_3/loss=1.079, pursuer_4/loss=0.964, pursuer_5/loss=1.126, pursuer_6/loss=1.064, pursuer_7/loss=1.210, rew=84.60]
Epoch #29: test_reward: 6.005375 Â± 27.048902, best_reward: 31.509187 Â± 21.994771 in #24
































Epoch #30: 20001it [01:04, 309.89it/s, env_step=600000, len=3096, n/ep=0, n/st=400, pursuer_0/loss=0.922, pursuer_1/loss=0.998, pursuer_2/loss=1.099, pursuer_3/loss=1.198, pursuer_4/loss=1.242, pursuer_5/loss=1.184, pursuer_6/loss=1.106, pursuer_7/loss=1.110, rew=72.39]
Epoch #31:   0%|          | 0/20000 [00:00<?, ?it/s]

































Epoch #31: 20001it [01:06, 301.73it/s, env_step=620000, len=3680, n/ep=0, n/st=400, pursuer_0/loss=1.026, pursuer_1/loss=1.132, pursuer_2/loss=1.328, pursuer_3/loss=1.268, pursuer_4/loss=1.224, pursuer_5/loss=1.244, pursuer_6/loss=1.235, pursuer_7/loss=1.303, rew=21.08]
Epoch #31: test_reward: 21.113437 Â± 32.356295, best_reward: 31.509187 Â± 21.994771 in #24


































Epoch #32: 20001it [01:07, 297.33it/s, env_step=640000, len=1936, n/ep=0, n/st=400, pursuer_0/loss=1.076, pursuer_1/loss=1.157, pursuer_2/loss=1.243, pursuer_3/loss=1.241, pursuer_4/loss=1.048, pursuer_5/loss=1.106, pursuer_6/loss=1.321, pursuer_7/loss=1.410, rew=81.47]
Epoch #32: test_reward: 29.766375 Â± 27.014244, best_reward: 31.509187 Â± 21.994771 in #24


































Epoch #33: 20001it [01:08, 293.33it/s, env_step=660000, len=4000, n/ep=0, n/st=400, pursuer_0/loss=0.976, pursuer_1/loss=1.219, pursuer_2/loss=1.047, pursuer_3/loss=1.264, pursuer_4/loss=1.159, pursuer_5/loss=1.255, pursuer_6/loss=1.192, pursuer_7/loss=1.220, rew=15.54]
Epoch #33: test_reward: 16.229562 Â± 26.286462, best_reward: 31.509187 Â± 21.994771 in #24

































Epoch #34: 20001it [01:07, 297.94it/s, env_step=680000, len=3600, n/ep=0, n/st=400, pursuer_0/loss=1.027, pursuer_1/loss=1.151, pursuer_2/loss=1.165, pursuer_3/loss=1.183, pursuer_4/loss=1.158, pursuer_5/loss=1.208, pursuer_6/loss=1.176, pursuer_7/loss=1.261, rew=-28.60]
Epoch #35:   0%|          | 0/20000 [00:00<?, ?it/s]


































Epoch #35: 20001it [01:08, 292.75it/s, env_step=700000, len=4000, n/ep=0, n/st=400, pursuer_0/loss=1.055, pursuer_1/loss=1.069, pursuer_2/loss=1.247, pursuer_3/loss=1.275, pursuer_4/loss=1.075, pursuer_5/loss=1.324, pursuer_6/loss=1.314, pursuer_7/loss=1.189, rew=50.82]
Epoch #36:   2%|2         | 400/20000 [00:00<00:25, 758.36it/s]



































Epoch #36: 20001it [01:09, 287.69it/s, env_step=720000, len=2320, n/ep=0, n/st=400, pursuer_0/loss=1.074, pursuer_1/loss=1.094, pursuer_2/loss=1.157, pursuer_3/loss=1.207, pursuer_4/loss=1.142, pursuer_5/loss=1.205, pursuer_6/loss=1.214, pursuer_7/loss=1.266, rew=71.75]
Best Saved
Epoch #36: test_reward: 33.152375 Â± 31.689109, best_reward: 33.152375 Â± 31.689109 in #36





































Epoch #37: 20001it [01:15, 264.12it/s, env_step=740000, len=1128, n/ep=0, n/st=400, pursuer_0/loss=1.002, pursuer_1/loss=1.295, pursuer_2/loss=1.162, pursuer_3/loss=1.280, pursuer_4/loss=0.991, pursuer_5/loss=1.166, pursuer_6/loss=1.185, pursuer_7/loss=1.320, rew=51.28]
Epoch #37: test_reward: 18.979750 Â± 28.254739, best_reward: 33.152375 Â± 31.689109 in #36


































Epoch #38: 20001it [01:09, 288.03it/s, env_step=760000, len=3664, n/ep=0, n/st=400, pursuer_0/loss=1.044, pursuer_1/loss=1.190, pursuer_2/loss=1.160, pursuer_3/loss=1.078, pursuer_4/loss=1.139, pursuer_5/loss=1.122, pursuer_6/loss=1.240, pursuer_7/loss=1.467, rew=14.95]
Epoch #39:   0%|          | 0/20000 [00:00<?, ?it/s]





























Epoch #39: 20001it [00:56, 351.13it/s, env_step=780000, len=3572, n/ep=0, n/st=400, pursuer_0/loss=1.059, pursuer_1/loss=1.249, pursuer_2/loss=1.227, pursuer_3/loss=1.121, pursuer_4/loss=1.176, pursuer_5/loss=1.176, pursuer_6/loss=1.339, pursuer_7/loss=1.217, rew=6.05]
Epoch #40:   2%|2         | 400/20000 [00:01<00:21, 891.97it/s, env_step=780400, len=3572, n/ep=0, n/st=400, pursuer_0/loss=1.076, pursuer_1/loss=1.211, pursuer_2/loss=1.185, pursuer_3/loss=1.147, pursuer_4/loss=1.122, pursuer_5/loss=1.162, pursuer_6/loss=1.316, pursuer_7/loss=1.218, rew=6.05]
Best Saved




























Epoch #40: 20001it [00:56, 354.25it/s, env_step=800000, len=1504, n/ep=0, n/st=400, pursuer_0/loss=1.098, pursuer_1/loss=1.129, pursuer_2/loss=1.293, pursuer_3/loss=1.219, pursuer_4/loss=1.157, pursuer_5/loss=1.210, pursuer_6/loss=1.280, pursuer_7/loss=1.266, rew=52.16]
Epoch #40: test_reward: 8.659500 Â± 23.969244, best_reward: 35.085687 Â± 35.607789 in #39



























Epoch #41: 20001it [00:56, 353.32it/s, env_step=820000, len=1816, n/ep=0, n/st=400, pursuer_0/loss=1.073, pursuer_1/loss=0.882, pursuer_2/loss=1.168, pursuer_3/loss=1.071, pursuer_4/loss=0.999, pursuer_5/loss=1.112, pursuer_6/loss=1.237, pursuer_7/loss=1.186, rew=27.98]
Epoch #42:   4%|4         | 800/20000 [00:01<00:39, 481.89it/s, env_step=820400, len=1816, n/ep=0, n/st=400, pursuer_0/loss=1.062, pursuer_1/loss=0.925, pursuer_2/loss=1.162, pursuer_3/loss=1.071, pursuer_4/loss=0.994, pursuer_5/loss=1.116, pursuer_6/loss=1.249, pursuer_7/loss=1.212, rew=27.98]




























Epoch #42: 20001it [00:56, 351.31it/s, env_step=840000, len=3720, n/ep=0, n/st=400, pursuer_0/loss=1.026, pursuer_1/loss=1.079, pursuer_2/loss=1.091, pursuer_3/loss=1.039, pursuer_4/loss=1.039, pursuer_5/loss=1.004, pursuer_6/loss=1.195, pursuer_7/loss=1.138, rew=18.88]
Epoch #43:   0%|          | 0/20000 [00:00<?, ?it/s]





























Epoch #43: 20001it [00:58, 344.67it/s, env_step=860000, len=2984, n/ep=0, n/st=400, pursuer_0/loss=1.119, pursuer_1/loss=1.134, pursuer_2/loss=1.161, pursuer_3/loss=1.116, pursuer_4/loss=1.237, pursuer_5/loss=1.222, pursuer_6/loss=1.358, pursuer_7/loss=1.267, rew=33.76]
Epoch #44:   2%|2         | 400/20000 [00:01<00:22, 870.79it/s, env_step=860400, len=2984, n/ep=0, n/st=400, pursuer_0/loss=1.136, pursuer_1/loss=1.185, pursuer_2/loss=1.173, pursuer_3/loss=1.117, pursuer_4/loss=1.202, pursuer_5/loss=1.270, pursuer_6/loss=1.373, pursuer_7/loss=1.238, rew=33.76]




























Epoch #44: 20001it [00:56, 354.14it/s, env_step=880000, len=2112, n/ep=0, n/st=400, pursuer_0/loss=1.005, pursuer_1/loss=1.078, pursuer_2/loss=1.126, pursuer_3/loss=1.269, pursuer_4/loss=1.066, pursuer_5/loss=1.256, pursuer_6/loss=1.177, pursuer_7/loss=1.273, rew=49.11]
Epoch #45:   2%|2         | 400/20000 [00:00<00:21, 930.68it/s]





























Epoch #45: 20001it [00:58, 343.57it/s, env_step=900000, len=1856, n/ep=1, n/st=400, pursuer_0/loss=1.063, pursuer_1/loss=1.098, pursuer_2/loss=1.085, pursuer_3/loss=1.213, pursuer_4/loss=1.268, pursuer_5/loss=1.171, pursuer_6/loss=1.209, pursuer_7/loss=1.266, rew=52.65]
Epoch #45: test_reward: 13.757375 Â± 25.332684, best_reward: 35.085687 Â± 35.607789 in #39






























Epoch #46: 20001it [00:59, 334.43it/s, env_step=920000, len=2352, n/ep=0, n/st=400, pursuer_0/loss=1.000, pursuer_1/loss=1.139, pursuer_2/loss=1.049, pursuer_3/loss=1.201, pursuer_4/loss=1.122, pursuer_5/loss=0.995, pursuer_6/loss=1.230, pursuer_7/loss=1.169, rew=32.12]
Epoch #46: test_reward: 14.351437 Â± 24.618217, best_reward: 35.085687 Â± 35.607789 in #39





























Epoch #47: 20001it [01:00, 330.74it/s, env_step=940000, len=3712, n/ep=2, n/st=400, pursuer_0/loss=1.065, pursuer_1/loss=1.086, pursuer_2/loss=0.979, pursuer_3/loss=1.193, pursuer_4/loss=1.170, pursuer_5/loss=1.043, pursuer_6/loss=1.223, pursuer_7/loss=1.297, rew=19.87]
Epoch #47: test_reward: 24.044312 Â± 26.112776, best_reward: 35.085687 Â± 35.607789 in #39































Epoch #48: 20001it [01:01, 326.49it/s, env_step=960000, len=4000, n/ep=0, n/st=400, pursuer_0/loss=1.040, pursuer_1/loss=1.079, pursuer_2/loss=1.078, pursuer_3/loss=1.178, pursuer_4/loss=0.988, pursuer_5/loss=1.108, pursuer_6/loss=1.075, pursuer_7/loss=1.122, rew=55.92]
Epoch #48: test_reward: 23.268000 Â± 29.451256, best_reward: 35.085687 Â± 35.607789 in #39






























Epoch #49: 20001it [01:00, 332.96it/s, env_step=980000, len=4000, n/ep=1, n/st=400, pursuer_0/loss=1.027, pursuer_1/loss=1.055, pursuer_2/loss=1.197, pursuer_3/loss=1.125, pursuer_4/loss=1.076, pursuer_5/loss=1.090, pursuer_6/loss=1.059, pursuer_7/loss=1.349, rew=50.93]
Epoch #49: test_reward: 21.775687 Â± 30.131139, best_reward: 35.085687 Â± 35.607789 in #39



























Epoch #50: 20001it [00:55, 363.40it/s, env_step=1000000, len=3124, n/ep=0, n/st=400, pursuer_0/loss=0.961, pursuer_1/loss=1.100, pursuer_2/loss=1.052, pursuer_3/loss=1.142, pursuer_4/loss=0.949, pursuer_5/loss=1.078, pursuer_6/loss=1.104, pursuer_7/loss=1.139, rew=46.90]
Epoch #50: test_reward: 27.198562 Â± 32.509629, best_reward: 35.085687 Â± 35.607789 in #39


























Epoch #51: 20001it [00:53, 376.93it/s, env_step=1020000, len=1064, n/ep=1, n/st=400, pursuer_0/loss=1.054, pursuer_1/loss=1.049, pursuer_2/loss=1.208, pursuer_3/loss=1.332, pursuer_4/loss=1.205, pursuer_5/loss=0.994, pursuer_6/loss=1.279, pursuer_7/loss=1.219, rew=47.23]
Epoch #52:   2%|2         | 400/20000 [00:00<00:20, 934.27it/s]



























Epoch #52: 20001it [00:53, 371.27it/s, env_step=1040000, len=1616, n/ep=0, n/st=400, pursuer_0/loss=1.007, pursuer_1/loss=0.997, pursuer_2/loss=1.094, pursuer_3/loss=1.116, pursuer_4/loss=1.091, pursuer_5/loss=1.107, pursuer_6/loss=1.239, pursuer_7/loss=1.081, rew=55.51]
Epoch #53:   0%|          | 0/20000 [00:00<?, ?it/s]


























Epoch #53: 20001it [00:51, 386.77it/s, env_step=1060000, len=3968, n/ep=0, n/st=400, pursuer_0/loss=0.930, pursuer_1/loss=0.981, pursuer_2/loss=1.033, pursuer_3/loss=1.130, pursuer_4/loss=1.072, pursuer_5/loss=1.057, pursuer_6/loss=1.099, pursuer_7/loss=1.081, rew=41.73]
Best Saved
Epoch #53: test_reward: 41.422812 Â± 28.226053, best_reward: 41.422812 Â± 28.226053 in #53



























Epoch #54: 20001it [00:53, 371.40it/s, env_step=1080000, len=1808, n/ep=1, n/st=400, pursuer_0/loss=1.070, pursuer_1/loss=1.029, pursuer_2/loss=0.999, pursuer_3/loss=1.095, pursuer_4/loss=1.089, pursuer_5/loss=1.056, pursuer_6/loss=1.159, pursuer_7/loss=1.189, rew=52.73]
Epoch #54: test_reward: 15.533062 Â± 31.524428, best_reward: 41.422812 Â± 28.226053 in #53


























Epoch #55: 20001it [00:52, 384.34it/s, env_step=1100000, len=1920, n/ep=0, n/st=400, pursuer_0/loss=0.943, pursuer_1/loss=1.041, pursuer_2/loss=0.977, pursuer_3/loss=1.142, pursuer_4/loss=1.018, pursuer_5/loss=1.117, pursuer_6/loss=1.117, pursuer_7/loss=1.108, rew=41.91]
Epoch #55: test_reward: 15.649125 Â± 29.089074, best_reward: 41.422812 Â± 28.226053 in #53


























Epoch #56: 20001it [00:52, 383.72it/s, env_step=1120000, len=3144, n/ep=0, n/st=400, pursuer_0/loss=0.874, pursuer_1/loss=0.895, pursuer_2/loss=1.023, pursuer_3/loss=1.001, pursuer_4/loss=1.012, pursuer_5/loss=1.120, pursuer_6/loss=1.129, pursuer_7/loss=1.113, rew=41.32]
Epoch #56: test_reward: 9.236875 Â± 30.212285, best_reward: 41.422812 Â± 28.226053 in #53


























Epoch #57: 20001it [00:53, 373.07it/s, env_step=1140000, len=3768, n/ep=0, n/st=400, pursuer_0/loss=0.930, pursuer_1/loss=1.066, pursuer_2/loss=1.109, pursuer_3/loss=1.200, pursuer_4/loss=1.033, pursuer_5/loss=1.168, pursuer_6/loss=1.079, pursuer_7/loss=1.249, rew=33.54]
Epoch #57: test_reward: 23.289375 Â± 37.794639, best_reward: 41.422812 Â± 28.226053 in #53





























Epoch #58: 20001it [00:58, 341.60it/s, env_step=1160000, len=1760, n/ep=0, n/st=400, pursuer_0/loss=1.052, pursuer_1/loss=0.966, pursuer_2/loss=1.059, pursuer_3/loss=1.075, pursuer_4/loss=1.091, pursuer_5/loss=1.113, pursuer_6/loss=1.125, pursuer_7/loss=1.169, rew=29.39]
Epoch #59:   0%|          | 0/20000 [00:00<?, ?it/s]





























Epoch #59: 20001it [00:57, 349.31it/s, env_step=1180000, len=4000, n/ep=0, n/st=400, pursuer_0/loss=0.988, pursuer_1/loss=0.861, pursuer_2/loss=1.039, pursuer_3/loss=1.095, pursuer_4/loss=0.928, pursuer_5/loss=1.060, pursuer_6/loss=1.084, pursuer_7/loss=1.113, rew=-4.41]
Epoch #60:   0%|          | 0/20000 [00:00<?, ?it/s]






























Epoch #60: 20001it [00:58, 339.24it/s, env_step=1200000, len=1800, n/ep=0, n/st=400, pursuer_0/loss=0.899, pursuer_1/loss=0.988, pursuer_2/loss=1.051, pursuer_3/loss=0.952, pursuer_4/loss=1.047, pursuer_5/loss=1.115, pursuer_6/loss=1.081, pursuer_7/loss=1.077, rew=13.03]
Epoch #61:   2%|2         | 400/20000 [00:00<00:21, 918.06it/s]





























Epoch #61: 20001it [00:57, 345.36it/s, env_step=1220000, len=4000, n/ep=0, n/st=400, pursuer_0/loss=0.937, pursuer_1/loss=1.032, pursuer_2/loss=1.039, pursuer_3/loss=1.223, pursuer_4/loss=0.987, pursuer_5/loss=1.031, pursuer_6/loss=1.080, pursuer_7/loss=1.272, rew=17.26]
d:\Python310\lib\site-packages\torch\nn\init.py:412: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
d:\Python310\lib\site-packages\torch\nn\init.py:412: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
d:\Python310\lib\site-packages\torch\nn\init.py:412: UserWarning: Initializing zero-element tensors is a no-op
