{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1:   3%|3         | 3000/100000 [00:02<01:09, 1397.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n",
      "agent pos: , agent_position.shape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1:   3%|3         | 3000/100000 [00:02<01:13, 1315.79it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 168\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[39mreturn\u001b[39;00m rews\u001b[39m.\u001b[39mmean()\u001b[39m#[:,0]\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[39m# ======== Step 5: Run the trainer =========\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m result \u001b[39m=\u001b[39m offpolicy_trainer(\n\u001b[0;32m    169\u001b[0m     policy\u001b[39m=\u001b[39;49mpolicy,\n\u001b[0;32m    170\u001b[0m     train_collector\u001b[39m=\u001b[39;49mtrain_collector,\n\u001b[0;32m    171\u001b[0m     test_collector\u001b[39m=\u001b[39;49mtest_collector,        \n\u001b[0;32m    172\u001b[0m     max_epoch\u001b[39m=\u001b[39;49m\u001b[39m10000\u001b[39;49m,\n\u001b[0;32m    173\u001b[0m     step_per_epoch\u001b[39m=\u001b[39;49m\u001b[39m10000\u001b[39;49m \u001b[39m*\u001b[39;49m train_env_num,\n\u001b[0;32m    174\u001b[0m     step_per_collect\u001b[39m=\u001b[39;49m\u001b[39m300\u001b[39;49m \u001b[39m*\u001b[39;49m train_env_num,\n\u001b[0;32m    175\u001b[0m     episode_per_test\u001b[39m=\u001b[39;49m \u001b[39m10\u001b[39;49m \u001b[39m*\u001b[39;49m test_env_num,\n\u001b[0;32m    176\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[0;32m    177\u001b[0m     train_fn\u001b[39m=\u001b[39;49mtrain_fn,\n\u001b[0;32m    178\u001b[0m     test_fn\u001b[39m=\u001b[39;49mtest_fn,\n\u001b[0;32m    179\u001b[0m     stop_fn\u001b[39m=\u001b[39;49mstop_fn,\n\u001b[0;32m    180\u001b[0m     save_best_fn\u001b[39m=\u001b[39;49msave_best_fn,\n\u001b[0;32m    181\u001b[0m     update_per_step\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m,\n\u001b[0;32m    182\u001b[0m     logger\u001b[39m=\u001b[39;49mlogger,\n\u001b[0;32m    183\u001b[0m     test_in_train\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    184\u001b[0m     reward_metric\u001b[39m=\u001b[39;49mreward_metric,\n\u001b[0;32m    185\u001b[0m     show_progress \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m    186\u001b[0m     )\n\u001b[0;32m    188\u001b[0m \u001b[39m# return result, policy.policies[agents[1]]\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m==========Result==========\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\tianshou\\trainer\\offpolicy.py:134\u001b[0m, in \u001b[0;36moffpolicy_trainer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moffpolicy_trainer\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Union[\u001b[39mfloat\u001b[39m, \u001b[39mstr\u001b[39m]]:  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Wrapper for OffPolicyTrainer run method.\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \n\u001b[0;32m    130\u001b[0m \u001b[39m    It is identical to ``OffpolicyTrainer(...).run()``.\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \n\u001b[0;32m    132\u001b[0m \u001b[39m    :return: See :func:`~tianshou.trainer.gather_info`.\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[39mreturn\u001b[39;00m OffpolicyTrainer(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\tianshou\\trainer\\base.py:441\u001b[0m, in \u001b[0;36mBaseTrainer.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    440\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_run \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 441\u001b[0m     deque(\u001b[39mself\u001b[39;49m, maxlen\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)  \u001b[39m# feed the entire iterator into a zero-length deque\u001b[39;00m\n\u001b[0;32m    442\u001b[0m     info \u001b[39m=\u001b[39m gather_info(\n\u001b[0;32m    443\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart_time, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_collector, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_collector,\n\u001b[0;32m    444\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_reward, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_reward_std\n\u001b[0;32m    445\u001b[0m     )\n\u001b[0;32m    446\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\tianshou\\trainer\\base.py:299\u001b[0m, in \u001b[0;36mBaseTrainer.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    296\u001b[0m         result[\u001b[39m\"\u001b[39m\u001b[39mn/st\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgradient_step)\n\u001b[0;32m    297\u001b[0m         t\u001b[39m.\u001b[39mupdate()\n\u001b[1;32m--> 299\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpolicy_update_fn(data, result)\n\u001b[0;32m    300\u001b[0m     t\u001b[39m.\u001b[39mset_postfix(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdata)\n\u001b[0;32m    302\u001b[0m \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mn \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m t\u001b[39m.\u001b[39mtotal \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_fn_flag:\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\tianshou\\trainer\\offpolicy.py:122\u001b[0m, in \u001b[0;36mOffpolicyTrainer.policy_update_fn\u001b[1;34m(self, data, result)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mround\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_per_step \u001b[39m*\u001b[39m result[\u001b[39m\"\u001b[39m\u001b[39mn/st\u001b[39m\u001b[39m\"\u001b[39m])):\n\u001b[0;32m    121\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgradient_step \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 122\u001b[0m     losses \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpolicy\u001b[39m.\u001b[39;49mupdate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_size, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_collector\u001b[39m.\u001b[39;49mbuffer)\n\u001b[0;32m    123\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_update_data(data, losses)\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\tianshou\\policy\\base.py:276\u001b[0m, in \u001b[0;36mBasePolicy.update\u001b[1;34m(self, sample_size, buffer, **kwargs)\u001b[0m\n\u001b[0;32m    274\u001b[0m batch, indices \u001b[39m=\u001b[39m buffer\u001b[39m.\u001b[39msample(sample_size)\n\u001b[0;32m    275\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdating \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 276\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess_fn(batch, buffer, indices)\n\u001b[0;32m    277\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlearn(batch, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    278\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_process_fn(batch, buffer, indices)\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\tianshou\\policy\\multiagent\\mapolicy.py:75\u001b[0m, in \u001b[0;36mMultiAgentPolicyManager.process_fn\u001b[1;34m(self, batch, buffer, indice)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(tmp_batch\u001b[39m.\u001b[39mobs_next, \u001b[39m'\u001b[39m\u001b[39mobs\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     74\u001b[0m             tmp_batch\u001b[39m.\u001b[39mobs_next \u001b[39m=\u001b[39m tmp_batch\u001b[39m.\u001b[39mobs_next\u001b[39m.\u001b[39mobs\n\u001b[1;32m---> 75\u001b[0m     results[agent] \u001b[39m=\u001b[39m policy\u001b[39m.\u001b[39;49mprocess_fn(tmp_batch, buffer, tmp_indice)\n\u001b[0;32m     76\u001b[0m \u001b[39mif\u001b[39;00m has_rew:  \u001b[39m# restore from save_rew\u001b[39;00m\n\u001b[0;32m     77\u001b[0m     buffer\u001b[39m.\u001b[39m_meta\u001b[39m.\u001b[39mrew \u001b[39m=\u001b[39m save_rew\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\tianshou\\policy\\modelfree\\dqn.py:106\u001b[0m, in \u001b[0;36mDQNPolicy.process_fn\u001b[1;34m(self, batch, buffer, indices)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_fn\u001b[39m(\n\u001b[0;32m     99\u001b[0m     \u001b[39mself\u001b[39m, batch: Batch, buffer: ReplayBuffer, indices: np\u001b[39m.\u001b[39mndarray\n\u001b[0;32m    100\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Batch:\n\u001b[0;32m    101\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the n-step return for Q-learning targets.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \n\u001b[0;32m    103\u001b[0m \u001b[39m    More details can be found at\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[39m    :meth:`~tianshou.policy.BasePolicy.compute_nstep_return`.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_nstep_return(\n\u001b[0;32m    107\u001b[0m         batch, buffer, indices, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_target_q, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gamma, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_n_step,\n\u001b[0;32m    108\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rew_norm\n\u001b[0;32m    109\u001b[0m     )\n\u001b[0;32m    110\u001b[0m     \u001b[39mreturn\u001b[39;00m batch\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\tianshou\\policy\\base.py:396\u001b[0m, in \u001b[0;36mBasePolicy.compute_nstep_return\u001b[1;34m(batch, buffer, indice, target_q_fn, gamma, n_step, rew_norm)\u001b[0m\n\u001b[0;32m    394\u001b[0m end_flag \u001b[39m=\u001b[39m buffer\u001b[39m.\u001b[39mdone\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    395\u001b[0m end_flag[buffer\u001b[39m.\u001b[39munfinished_index()] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 396\u001b[0m target_q \u001b[39m=\u001b[39m _nstep_return(rew, end_flag, target_q, indices, gamma, n_step)\n\u001b[0;32m    398\u001b[0m batch\u001b[39m.\u001b[39mreturns \u001b[39m=\u001b[39m to_torch_as(target_q, target_q_torch)\n\u001b[0;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(batch, \u001b[39m\"\u001b[39m\u001b[39mweight\u001b[39m\u001b[39m\"\u001b[39m):  \u001b[39m# prio buffer update\u001b[39;00m\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\numba\\core\\dispatcher.py:420\u001b[0m, in \u001b[0;36m_DispatcherBase._compile_for_args\u001b[1;34m(self, *args, **kws)\u001b[0m\n\u001b[0;32m    418\u001b[0m return_val \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     return_val \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompile(\u001b[39mtuple\u001b[39;49m(argtypes))\n\u001b[0;32m    421\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mForceLiteralArg \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    422\u001b[0m     \u001b[39m# Received request for compiler re-entry with the list of arguments\u001b[39;00m\n\u001b[0;32m    423\u001b[0m     \u001b[39m# indicated by e.requested_args.\u001b[39;00m\n\u001b[0;32m    424\u001b[0m     \u001b[39m# First, check if any of these args are already Literal-ized\u001b[39;00m\n\u001b[0;32m    425\u001b[0m     already_lit_pos \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m e\u001b[39m.\u001b[39mrequested_args\n\u001b[0;32m    426\u001b[0m                        \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(args[i], types\u001b[39m.\u001b[39mLiteral)]\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\numba\\core\\dispatcher.py:965\u001b[0m, in \u001b[0;36mDispatcher.compile\u001b[1;34m(self, sig)\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[39mwith\u001b[39;00m ev\u001b[39m.\u001b[39mtrigger_event(\u001b[39m\"\u001b[39m\u001b[39mnumba:compile\u001b[39m\u001b[39m\"\u001b[39m, data\u001b[39m=\u001b[39mev_details):\n\u001b[0;32m    964\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 965\u001b[0m         cres \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compiler\u001b[39m.\u001b[39;49mcompile(args, return_type)\n\u001b[0;32m    966\u001b[0m     \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mForceLiteralArg \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    967\u001b[0m         \u001b[39mdef\u001b[39;00m \u001b[39mfolded\u001b[39m(args, kws):\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\numba\\core\\dispatcher.py:125\u001b[0m, in \u001b[0;36m_FunctionCompiler.compile\u001b[1;34m(self, args, return_type)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompile\u001b[39m(\u001b[39mself\u001b[39m, args, return_type):\n\u001b[1;32m--> 125\u001b[0m     status, retval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compile_cached(args, return_type)\n\u001b[0;32m    126\u001b[0m     \u001b[39mif\u001b[39;00m status:\n\u001b[0;32m    127\u001b[0m         \u001b[39mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\numba\\core\\dispatcher.py:139\u001b[0m, in \u001b[0;36m_FunctionCompiler._compile_cached\u001b[1;34m(self, args, return_type)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 139\u001b[0m     retval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compile_core(args, return_type)\n\u001b[0;32m    140\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mTypingError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    141\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_failed_cache[key] \u001b[39m=\u001b[39m e\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\numba\\core\\dispatcher.py:152\u001b[0m, in \u001b[0;36m_FunctionCompiler._compile_core\u001b[1;34m(self, args, return_type)\u001b[0m\n\u001b[0;32m    149\u001b[0m flags \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_customize_flags(flags)\n\u001b[0;32m    151\u001b[0m impl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_implementation(args, {})\n\u001b[1;32m--> 152\u001b[0m cres \u001b[39m=\u001b[39m compiler\u001b[39m.\u001b[39;49mcompile_extra(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtargetdescr\u001b[39m.\u001b[39;49mtyping_context,\n\u001b[0;32m    153\u001b[0m                               \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtargetdescr\u001b[39m.\u001b[39;49mtarget_context,\n\u001b[0;32m    154\u001b[0m                               impl,\n\u001b[0;32m    155\u001b[0m                               args\u001b[39m=\u001b[39;49margs, return_type\u001b[39m=\u001b[39;49mreturn_type,\n\u001b[0;32m    156\u001b[0m                               flags\u001b[39m=\u001b[39;49mflags, \u001b[39mlocals\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlocals,\n\u001b[0;32m    157\u001b[0m                               pipeline_class\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpipeline_class)\n\u001b[0;32m    158\u001b[0m \u001b[39m# Check typing error if object mode is used\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[39mif\u001b[39;00m cres\u001b[39m.\u001b[39mtyping_error \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m flags\u001b[39m.\u001b[39menable_pyobject:\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\numba\\core\\compiler.py:716\u001b[0m, in \u001b[0;36mcompile_extra\u001b[1;34m(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class)\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compiler entry point\u001b[39;00m\n\u001b[0;32m    693\u001b[0m \n\u001b[0;32m    694\u001b[0m \u001b[39mParameter\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    712\u001b[0m \u001b[39m    compiler pipeline\u001b[39;00m\n\u001b[0;32m    713\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    714\u001b[0m pipeline \u001b[39m=\u001b[39m pipeline_class(typingctx, targetctx, library,\n\u001b[0;32m    715\u001b[0m                           args, return_type, flags, \u001b[39mlocals\u001b[39m)\n\u001b[1;32m--> 716\u001b[0m \u001b[39mreturn\u001b[39;00m pipeline\u001b[39m.\u001b[39;49mcompile_extra(func)\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\numba\\core\\compiler.py:452\u001b[0m, in \u001b[0;36mCompilerBase.compile_extra\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mlifted \u001b[39m=\u001b[39m ()\n\u001b[0;32m    451\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mlifted_from \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 452\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compile_bytecode()\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\numba\\core\\compiler.py:520\u001b[0m, in \u001b[0;36mCompilerBase._compile_bytecode\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    517\u001b[0m \u001b[39mPopulate and run pipeline for bytecode input\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    519\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfunc_ir \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 520\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compile_core()\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\numba\\core\\compiler.py:486\u001b[0m, in \u001b[0;36mCompilerBase._compile_core\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    484\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     pm\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstate)\n\u001b[0;32m    487\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mcr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    488\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\numba\\core\\compiler_machinery.py:356\u001b[0m, in \u001b[0;36mPassManager.run\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    354\u001b[0m pass_inst \u001b[39m=\u001b[39m _pass_registry\u001b[39m.\u001b[39mget(pss)\u001b[39m.\u001b[39mpass_inst\n\u001b[0;32m    355\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(pass_inst, CompilerPass):\n\u001b[1;32m--> 356\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_runPass(idx, pass_inst, state)\n\u001b[0;32m    357\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    358\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mBaseException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mLegacy pass in use\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\numba\\core\\compiler_lock.py:35\u001b[0m, in \u001b[0;36m_CompilerLock.__call__.<locals>._acquire_compile_lock\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_acquire_compile_lock\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     34\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m---> 35\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\numba\\core\\compiler_machinery.py:311\u001b[0m, in \u001b[0;36mPassManager._runPass\u001b[1;34m(self, index, pss, internal_state)\u001b[0m\n\u001b[0;32m    309\u001b[0m     mutated \u001b[39m|\u001b[39m\u001b[39m=\u001b[39m check(pss\u001b[39m.\u001b[39mrun_initialization, internal_state)\n\u001b[0;32m    310\u001b[0m \u001b[39mwith\u001b[39;00m SimpleTimer() \u001b[39mas\u001b[39;00m pass_time:\n\u001b[1;32m--> 311\u001b[0m     mutated \u001b[39m|\u001b[39m\u001b[39m=\u001b[39m check(pss\u001b[39m.\u001b[39;49mrun_pass, internal_state)\n\u001b[0;32m    312\u001b[0m \u001b[39mwith\u001b[39;00m SimpleTimer() \u001b[39mas\u001b[39;00m finalize_time:\n\u001b[0;32m    313\u001b[0m     mutated \u001b[39m|\u001b[39m\u001b[39m=\u001b[39m check(pss\u001b[39m.\u001b[39mrun_finalizer, internal_state)\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\numba\\core\\compiler_machinery.py:273\u001b[0m, in \u001b[0;36mPassManager._runPass.<locals>.check\u001b[1;34m(func, compiler_state)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck\u001b[39m(func, compiler_state):\n\u001b[1;32m--> 273\u001b[0m     mangled \u001b[39m=\u001b[39m func(compiler_state)\n\u001b[0;32m    274\u001b[0m     \u001b[39mif\u001b[39;00m mangled \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    275\u001b[0m         msg \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mCompilerPass implementations should return True/False. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    276\u001b[0m                \u001b[39m\"\u001b[39m\u001b[39mCompilerPass with name \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m did not.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\numba\\core\\typed_passes.py:394\u001b[0m, in \u001b[0;36mNativeLowering.run_pass\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[39mwith\u001b[39;00m targetctx\u001b[39m.\u001b[39mpush_code_library(library):\n\u001b[0;32m    392\u001b[0m     lower \u001b[39m=\u001b[39m lowering\u001b[39m.\u001b[39mLower(targetctx, library, fndesc, interp,\n\u001b[0;32m    393\u001b[0m                            metadata\u001b[39m=\u001b[39mmetadata)\n\u001b[1;32m--> 394\u001b[0m     lower\u001b[39m.\u001b[39;49mlower()\n\u001b[0;32m    395\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m flags\u001b[39m.\u001b[39mno_cpython_wrapper:\n\u001b[0;32m    396\u001b[0m         lower\u001b[39m.\u001b[39mcreate_cpython_wrapper(flags\u001b[39m.\u001b[39mrelease_gil)\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\numba\\core\\lowering.py:168\u001b[0m, in \u001b[0;36mBaseLower.lower\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerator_info \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    167\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenlower \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlower_normal_function(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfndesc)\n\u001b[0;32m    169\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenlower \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mGeneratorLower(\u001b[39mself\u001b[39m)\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\numba\\core\\lowering.py:222\u001b[0m, in \u001b[0;36mBaseLower.lower_normal_function\u001b[1;34m(self, fndesc)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[39m# Init argument values\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextract_function_arguments()\n\u001b[1;32m--> 222\u001b[0m entry_block_tail \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlower_function_body()\n\u001b[0;32m    224\u001b[0m \u001b[39m# Close tail of entry block, do not emit debug metadata else the\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[39m# unconditional jump gets associated with the metadata from the function\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[39m# body end.\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[39mwith\u001b[39;00m debuginfo\u001b[39m.\u001b[39msuspend_emission(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder):\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\numba\\core\\lowering.py:251\u001b[0m, in \u001b[0;36mBaseLower.lower_function_body\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m     bb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblkmap[offset]\n\u001b[0;32m    250\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39mposition_at_end(bb)\n\u001b[1;32m--> 251\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlower_block(block)\n\u001b[0;32m    252\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_lower()\n\u001b[0;32m    253\u001b[0m \u001b[39mreturn\u001b[39;00m entry_block_tail\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\numba\\core\\lowering.py:265\u001b[0m, in \u001b[0;36mBaseLower.lower_block\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m    262\u001b[0m     defaulterrcls \u001b[39m=\u001b[39m partial(LoweringError, loc\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloc)\n\u001b[0;32m    263\u001b[0m     \u001b[39mwith\u001b[39;00m new_error_context(\u001b[39m'\u001b[39m\u001b[39mlowering \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{inst}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m at \u001b[39m\u001b[39m{loc}\u001b[39;00m\u001b[39m'\u001b[39m, inst\u001b[39m=\u001b[39minst,\n\u001b[0;32m    264\u001b[0m                            loc\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloc, errcls_\u001b[39m=\u001b[39mdefaulterrcls):\n\u001b[1;32m--> 265\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlower_inst(inst)\n\u001b[0;32m    266\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_block(block)\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\numba\\core\\lowering.py:439\u001b[0m, in \u001b[0;36mLower.lower_inst\u001b[1;34m(self, inst)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(inst, ir\u001b[39m.\u001b[39mAssign):\n\u001b[0;32m    438\u001b[0m     ty \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtypeof(inst\u001b[39m.\u001b[39mtarget\u001b[39m.\u001b[39mname)\n\u001b[1;32m--> 439\u001b[0m     val \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlower_assign(ty, inst)\n\u001b[0;32m    440\u001b[0m     argidx \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    441\u001b[0m     \u001b[39m# If this is a store from an arg, like x = arg.x then tell debuginfo\u001b[39;00m\n\u001b[0;32m    442\u001b[0m     \u001b[39m# that this is the arg\u001b[39;00m\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\numba\\core\\lowering.py:626\u001b[0m, in \u001b[0;36mLower.lower_assign\u001b[1;34m(self, ty, inst)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[0;32m    625\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, ir\u001b[39m.\u001b[39mExpr):\n\u001b[1;32m--> 626\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlower_expr(ty, value)\n\u001b[0;32m    628\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, ir\u001b[39m.\u001b[39mVar):\n\u001b[0;32m    629\u001b[0m     val \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloadvar(value\u001b[39m.\u001b[39mname)\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\numba\\core\\lowering.py:1297\u001b[0m, in \u001b[0;36mLower.lower_expr\u001b[1;34m(self, resty, expr)\u001b[0m\n\u001b[0;32m   1295\u001b[0m \u001b[39melif\u001b[39;00m expr\u001b[39m.\u001b[39mop \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgetitem\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1296\u001b[0m     signature \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfndesc\u001b[39m.\u001b[39mcalltypes[expr]\n\u001b[1;32m-> 1297\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlower_getitem(resty, expr, expr\u001b[39m.\u001b[39;49mvalue, expr\u001b[39m.\u001b[39;49mindex,\n\u001b[0;32m   1298\u001b[0m                               signature)\n\u001b[0;32m   1300\u001b[0m \u001b[39melif\u001b[39;00m expr\u001b[39m.\u001b[39mop \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbuild_tuple\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1301\u001b[0m     itemvals \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloadvar(i\u001b[39m.\u001b[39mname) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m expr\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\numba\\core\\lowering.py:767\u001b[0m, in \u001b[0;36mLower.lower_getitem\u001b[1;34m(self, resty, expr, value, index, signature)\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[39m# Get implementation of getitem\u001b[39;00m\n\u001b[0;32m    766\u001b[0m op \u001b[39m=\u001b[39m operator\u001b[39m.\u001b[39mgetitem\n\u001b[1;32m--> 767\u001b[0m fnop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcontext\u001b[39m.\u001b[39;49mtyping_context\u001b[39m.\u001b[39;49mresolve_value_type(op)\n\u001b[0;32m    768\u001b[0m callsig \u001b[39m=\u001b[39m fnop\u001b[39m.\u001b[39mget_call_type(\n\u001b[0;32m    769\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontext\u001b[39m.\u001b[39mtyping_context, signature\u001b[39m.\u001b[39margs, {},\n\u001b[0;32m    770\u001b[0m )\n\u001b[0;32m    771\u001b[0m impl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontext\u001b[39m.\u001b[39mget_function(fnop, callsig)\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\numba\\core\\typing\\context.py:381\u001b[0m, in \u001b[0;36mBaseContext.resolve_value_type\u001b[1;34m(self, val)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \u001b[39mReturn the numba type of a Python value that is being used\u001b[39;00m\n\u001b[0;32m    377\u001b[0m \u001b[39mas a runtime constant.\u001b[39;00m\n\u001b[0;32m    378\u001b[0m \u001b[39mValueError is raised for unsupported types.\u001b[39;00m\n\u001b[0;32m    379\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     ty \u001b[39m=\u001b[39m typeof(val, Purpose\u001b[39m.\u001b[39;49mconstant)\n\u001b[0;32m    382\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    383\u001b[0m     \u001b[39m# Make sure the exception doesn't hold a reference to the user\u001b[39;00m\n\u001b[0;32m    384\u001b[0m     \u001b[39m# value.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m     typeof_exc \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39merase_traceback(e)\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\numba\\core\\typing\\typeof.py:40\u001b[0m, in \u001b[0;36mtypeof\u001b[1;34m(val, purpose)\u001b[0m\n\u001b[0;32m     38\u001b[0m ty \u001b[39m=\u001b[39m typeof_impl(val, c)\n\u001b[0;32m     39\u001b[0m \u001b[39mif\u001b[39;00m ty \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 40\u001b[0m     msg \u001b[39m=\u001b[39m _termcolor\u001b[39m.\u001b[39;49merrmsg(\n\u001b[0;32m     41\u001b[0m         \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mCannot determine Numba type of \u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mtype\u001b[39;49m(val)\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     42\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m     43\u001b[0m \u001b[39mreturn\u001b[39;00m ty\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\numba\\core\\errors.py:317\u001b[0m, in \u001b[0;36mHighlightColorScheme.errmsg\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39merrmsg\u001b[39m(\u001b[39mself\u001b[39m, msg):\n\u001b[1;32m--> 317\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_markup(msg, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_errmsg)\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\numba\\core\\errors.py:307\u001b[0m, in \u001b[0;36mHighlightColorScheme._markup\u001b[1;34m(self, msg, color, style)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m style:\n\u001b[0;32m    306\u001b[0m     features \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m style\n\u001b[1;32m--> 307\u001b[0m \u001b[39mwith\u001b[39;00m ColorShell():\n\u001b[0;32m    308\u001b[0m     \u001b[39mwith\u001b[39;00m reset_terminal() \u001b[39mas\u001b[39;00m mu:\n\u001b[0;32m    309\u001b[0m         mu \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m features\u001b[39m.\u001b[39mencode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\numba\\core\\errors.py:225\u001b[0m, in \u001b[0;36mColorShell.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 225\u001b[0m     init()\n\u001b[0;32m    226\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_initialized \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\colorama\\initialise.py:52\u001b[0m, in \u001b[0;36minit\u001b[1;34m(autoreset, convert, strip, wrap)\u001b[0m\n\u001b[0;32m     49\u001b[0m     wrapped_stdout \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     sys\u001b[39m.\u001b[39mstdout \u001b[39m=\u001b[39m wrapped_stdout \u001b[39m=\u001b[39m \\\n\u001b[1;32m---> 52\u001b[0m         wrap_stream(orig_stdout, convert, strip, autoreset, wrap)\n\u001b[0;32m     53\u001b[0m \u001b[39mif\u001b[39;00m sys\u001b[39m.\u001b[39mstderr \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     wrapped_stderr \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\colorama\\initialise.py:113\u001b[0m, in \u001b[0;36mwrap_stream\u001b[1;34m(stream, convert, strip, autoreset, wrap)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap_stream\u001b[39m(stream, convert, strip, autoreset, wrap):\n\u001b[0;32m    112\u001b[0m     \u001b[39mif\u001b[39;00m wrap:\n\u001b[1;32m--> 113\u001b[0m         wrapper \u001b[39m=\u001b[39m AnsiToWin32(stream,\n\u001b[0;32m    114\u001b[0m             convert\u001b[39m=\u001b[39;49mconvert, strip\u001b[39m=\u001b[39;49mstrip, autoreset\u001b[39m=\u001b[39;49mautoreset)\n\u001b[0;32m    115\u001b[0m         \u001b[39mif\u001b[39;00m wrapper\u001b[39m.\u001b[39mshould_wrap():\n\u001b[0;32m    116\u001b[0m             stream \u001b[39m=\u001b[39m wrapper\u001b[39m.\u001b[39mstream\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\colorama\\ansitowin32.py:96\u001b[0m, in \u001b[0;36mAnsiToWin32.__init__\u001b[1;34m(self, wrapped, convert, strip, autoreset)\u001b[0m\n\u001b[0;32m     91\u001b[0m on_windows \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnt\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     92\u001b[0m \u001b[39m# We test if the WinAPI works, because even if we are on Windows\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[39m# we may be using a terminal that doesn't support the WinAPI\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[39m# (e.g. Cygwin Terminal). In this case it's up to the terminal\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39m# to support the ANSI codes.\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m conversion_supported \u001b[39m=\u001b[39m on_windows \u001b[39mand\u001b[39;00m winapi_test()\n\u001b[0;32m     97\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     98\u001b[0m     fd \u001b[39m=\u001b[39m wrapped\u001b[39m.\u001b[39mfileno()\n",
      "File \u001b[1;32mw:\\OneDrive\\Doutorado\\SwarmSimASA\\PettingZoo\\lib\\site-packages\\colorama\\win32.py:116\u001b[0m, in \u001b[0;36mwinapi_test\u001b[1;34m()\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwinapi_test\u001b[39m():\n\u001b[0;32m    115\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39many\u001b[39m(_winapi_test(h) \u001b[39mfor\u001b[39;00m h \u001b[39min\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m                (_GetStdHandle(STDOUT), _GetStdHandle(STDERR)))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "from tianshou.data import Collector, VectorReplayBuffer\n",
    "from tianshou.env import DummyVectorEnv\n",
    "from tianshou.env.pettingzoo_env import PettingZooEnv\n",
    "from tianshou.policy import BasePolicy, DQNPolicy, MultiAgentPolicyManager, RandomPolicy\n",
    "from tianshou.trainer import offpolicy_trainer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tianshou.utils import TensorboardLogger\n",
    "\n",
    "\n",
    "#from Custom_Classes import CustomNet\n",
    "from Custom_Classes import CustomCollector\n",
    "from Custom_Classes import CustomParallelToAECWrapper\n",
    "\n",
    "from CustomClass_multi_head import CustomNet\n",
    "from Custom_Classes_simplified import CustomNetSimple\n",
    "from Custom_Classes_simplified import CustomCollectorSimple\n",
    "from Custom_Classes_simplified import CustomParallelToAECWrapperSimple\n",
    "\n",
    "from DroneEnv import MultiDroneEnv\n",
    "\n",
    "\n",
    "model_load_path = os.path.join(\"dqn_Custom\", \"policy_03.pth\")    \n",
    "load_model = False   \n",
    "\n",
    "def _get_agents(\n",
    "    agent_learn: Optional[BasePolicy] = None,\n",
    "    agent_opponent: Optional[BasePolicy] = None,\n",
    "    optim: Optional[torch.optim.Optimizer] = None,\n",
    "    policy_load_path = None\n",
    ") -> Tuple[BasePolicy, torch.optim.Optimizer, list]:\n",
    "    \n",
    "    env = _get_env()\n",
    "    agent_name = env.agents[0]  # Get the name of the first agent\n",
    "    agent_observation_space = env.observation_space[agent_name]  # Get the observation_space for that agent\n",
    "       \n",
    "    agent_observation_space = env.observation_space[\"agent0\"]  # assuming 'agent0' is a valid agent name\n",
    "    state_shape_agent_position = agent_observation_space[\"agent_position\"].shape[0]\n",
    "    state_shape_agent_state = agent_observation_space[\"agent_state\"].shape[0]\n",
    "    state_shape_agent_type = agent_observation_space[\"agent_type\"].shape[0]\n",
    "    state_shape_next_free_time = agent_observation_space[\"next_free_time\"].shape[0]\n",
    "    state_shape_position_after_last_task = agent_observation_space[\"position_after_last_task\"].shape[0]       \n",
    "    #state_shape_agent_relay_area = agent_observation_space[\"agent_relay_area\"].shape[0]\n",
    "    \n",
    "    \n",
    "    state_shape_agent = (state_shape_agent_position + state_shape_agent_state +\n",
    "                     state_shape_agent_type+ state_shape_next_free_time + state_shape_position_after_last_task #+                     \n",
    "                     #state_shape_agent_relay_area\n",
    "                     )                 \n",
    "    \n",
    "\n",
    "    state_shape_task = env.observation_space[\"agent0\"][\"tasks_info\"].shape[0]\n",
    "                  \n",
    "    action_shape = env.action_space[agent_name].shape[0]\n",
    "    #action_shape = env.action_space[agent_name].n\n",
    "               \n",
    "    if agent_learn is None:\n",
    "        # model\n",
    "        net = CustomNetSimple(\n",
    "        #net = CustomNet(\n",
    "            state_shape_agent=state_shape_agent,\n",
    "            state_shape_task=state_shape_task,\n",
    "            action_shape=action_shape,\n",
    "            hidden_sizes=[128,128],\n",
    "            device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        ).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "        if optim is None:\n",
    "            optim = torch.optim.Adam(net.parameters(), lr=5e-4)\n",
    "    \n",
    "        agent_learn = DQNPolicy(\n",
    "            model=net,\n",
    "            optim=optim,\n",
    "            discount_factor=0.7,\n",
    "            estimation_step=20,\n",
    "            target_update_freq=100,\n",
    "        )  \n",
    "        \n",
    "        if load_model == True:\n",
    "            # Load the saved checkpoint             \n",
    "            agent_learn.load_state_dict(torch.load(model_load_path))\n",
    "            print(\"loaded\")\n",
    "            \n",
    "        \n",
    "        agents = [agent_learn for _ in range(len(env.agents))]\n",
    "        \n",
    "    policy = MultiAgentPolicyManager(agents, env)    \n",
    "        \n",
    "    return policy, optim, env.agents\n",
    "\n",
    "\n",
    "def _get_env():\n",
    "    \"\"\"This function is needed to provide callables for DummyVectorEnv.\"\"\"\n",
    "    env_paralell = MultiDroneEnv()\n",
    "    #env = parallel_to_aec_wrapper(env_paralell)    \n",
    "    env = CustomParallelToAECWrapper(env_paralell)\n",
    "    \n",
    "    return PettingZooEnv(env)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "            \n",
    "    train_env_num = 10\n",
    "    test_env_num = 10\n",
    "        \n",
    "    \n",
    "    torch.set_grad_enabled(True) \n",
    "    # ======== Step 1: Environment setup =========\n",
    "    train_envs = DummyVectorEnv([_get_env for _ in range(train_env_num)])\n",
    "    test_envs = DummyVectorEnv([_get_env for _ in range(test_env_num)]) \n",
    "\n",
    "    # seed\n",
    "    seed = 1\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    torch.manual_seed(seed)\n",
    "    train_envs.seed(seed)\n",
    "    test_envs.seed(seed)\n",
    "\n",
    "    # ======== Step 2: Agent setup =========\n",
    "    policy, optim, agents = _get_agents()\n",
    "    \n",
    "\n",
    "    # ======== Step 3: Collector setup =========\n",
    "    train_collector = CustomCollector(\n",
    "        policy,\n",
    "        train_envs,\n",
    "        VectorReplayBuffer(100_000, len(train_envs)),\n",
    "        exploration_noise=True,\n",
    "    )\n",
    "    test_collector = CustomCollector(policy, test_envs, exploration_noise=True)\n",
    "     \n",
    "    train_collector.collect(n_step=1000)  # batch size * training_num\n",
    "    #test_collector.collect(n_step=1000) \n",
    "    \n",
    "    # ======== tensorboard logging setup =========\n",
    "    log_path = os.path.join('./', \"Logs\", \"dqn\")\n",
    "    writer = SummaryWriter(log_path)\n",
    "    #writer.add_text(\"args\", str(args))\n",
    "    logger = TensorboardLogger(writer)\n",
    "        \n",
    "    # ======== Step 4: Callback functions setup =========\n",
    "    def save_best_fn(policy):\n",
    "        model_save_path = os.path.join(\"dqn_Custom\", \"policy_03.pth\")        \n",
    "        os.makedirs(os.path.join(\"dqn_Custom\"), exist_ok=True)\n",
    "        torch.save(policy.policies[agents[0]].state_dict(), model_save_path)\n",
    "\n",
    "    def stop_fn(mean_rewards):\n",
    "        return mean_rewards >= 9939.0\n",
    "\n",
    "    def train_fn(epoch, env_step):\n",
    "        epsilon = max(0.5, 0.5 - epoch * 0.0005)\n",
    "        policy.policies[agents[0]].set_eps(epsilon)\n",
    "\n",
    "    def test_fn(epoch, env_step):\n",
    "        epsilon = 0.01#max(0.05, 0.1 - epoch * 0.001)\n",
    "        policy.policies[agents[0]].set_eps(epsilon)\n",
    "        \n",
    "    def reward_metric(rews):       \n",
    "        #print(rews)\n",
    "        return rews.mean()#[:,0]\n",
    "                           \n",
    "    # ======== Step 5: Run the trainer =========\n",
    "    result = offpolicy_trainer(\n",
    "        policy=policy,\n",
    "        train_collector=train_collector,\n",
    "        test_collector=test_collector,        \n",
    "        max_epoch=10000,\n",
    "        step_per_epoch=10000 * train_env_num,\n",
    "        step_per_collect=300 * train_env_num,\n",
    "        episode_per_test= 10 * test_env_num,\n",
    "        batch_size=32,\n",
    "        train_fn=train_fn,\n",
    "        test_fn=test_fn,\n",
    "        stop_fn=stop_fn,\n",
    "        save_best_fn=save_best_fn,\n",
    "        update_per_step=0.1,\n",
    "        logger=logger,\n",
    "        test_in_train=False,\n",
    "        reward_metric=reward_metric,\n",
    "        show_progress = True\n",
    "        )\n",
    "\n",
    "    # return result, policy.policies[agents[1]]\n",
    "    print(f\"\\n==========Result==========\\n{result}\")\n",
    "    print(\"\\n(the trained policy can be accessed via policy.policies[agents[0]])\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tianshou.env import DummyVectorEnv\n",
    "from tianshou.trainer import offpolicy_trainer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tianshou.utils import TensorboardLogger\n",
    "import torch\n",
    "#from Custom_Classes import CustomCollector\n",
    "\n",
    "# Create a new instance of the policy with the same architecture as the saved policy\n",
    "policy, optim, _ = _get_agents()\n",
    "model_save_path = os.path.join(\"dqn_Custom\", \"policy_03.pth\")        \n",
    "\n",
    "# Load the saved checkpoint\n",
    "policy_test = policy.policies['agent0']\n",
    "policy_test.load_state_dict(torch.load(model_save_path ))\n",
    "\n",
    "envs = DummyVectorEnv([_get_env for _ in range(1)])\n",
    "\n",
    "#policy_test.policies['agent0'].eval()\n",
    "#policy.policies['agent0'].set_eps(0.9)\n",
    "\n",
    "policy_test.eval()\n",
    "policy_test.set_eps(0.00)\n",
    "\n",
    "#collector = CustomCollector(policy.policies['agent0'], envs, exploration_noise=True)\n",
    "collector = CustomCollector(policy_test, envs, exploration_noise=True)\n",
    "\n",
    "#collector.collect(n_episode=10)\n",
    "collector.collect(n_episode=1, render=1 / 5000)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PettingZoo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
