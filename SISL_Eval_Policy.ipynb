{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python310\\lib\\site-packages\\torch\\nn\\init.py:412: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FinalRew:  [492.43875 616.34375 407.63875 723.82    845.8725 ]\n",
      "Finisehd:  [1064  920 1376 1200  832]  Steps\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional, Tuple\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from tianshou.env import DummyVectorEnv\n",
    "\n",
    "import torch\n",
    "\n",
    "from pettingzoo.sisl import pursuit_v4\n",
    "from TaskAllocation.RL_Policies.MultiHead_SISL import MultiHead_SISL\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tianshou.env import DummyVectorEnv\n",
    "from tianshou.env.pettingzoo_env import PettingZooEnv\n",
    "from tianshou.policy import BasePolicy, DQNPolicy, MultiAgentPolicyManager, RandomPolicy, RainbowPolicy\n",
    "from TaskAllocation.RL_Policies.CNN_SISL import CNN_SISL\n",
    "\n",
    "from pettingzoo.sisl import pursuit_v4\n",
    "\n",
    "from TaskAllocation.RL_Policies.MultiHead_SISL import MultiHead_SISL\n",
    "from TaskAllocation.RL_Policies.DNN_SISL import DNN_SISL\n",
    "\n",
    "from TaskAllocation.RL_Policies.Custom_Classes import CustomCollector\n",
    "\n",
    "#from tianshou_DQN import train\n",
    "model = \"CNN_SISL\" #\"MultiHead_SISL\" \n",
    "policyModel = \"DQN\"\n",
    "\n",
    "size = [16,16]\n",
    "n_agents = 8\n",
    "n_targes = 30\n",
    "max_cycles = 500\n",
    "obs_range = 7\n",
    "render = False\n",
    "\n",
    "seed = 0\n",
    "\n",
    "# Create a new instance of the policy with the same architecture as the saved policy\n",
    "# name = 'policy_CNN_SISL_01_Hot46231121-161700_2497_' \n",
    "name = 'policy_CNN_SISL_SISL_NOV12_Emb128231120-134122_5079' \n",
    "# name = 'policy_CNN_SISL_SISL_NOV12_ASAFull'\n",
    "\n",
    "Policy_Config = {\n",
    "    \"same_policy\" : True,\n",
    "    \"load_model\" : True,\n",
    "    \"freeze_CNN\" : True    \n",
    "                }\n",
    "\n",
    "dqn_params = {\"discount_factor\": 0.99, \n",
    "              \"estimation_step\": 1, \n",
    "              \"target_update_freq\": 800 * 4,\n",
    "              \"optminizer\": \"Adam\",\n",
    "              \"lr\": 1e-4 }\n",
    "\n",
    "trainer_params = {\"max_epoch\": 500,\n",
    "                  \"step_per_epoch\": 10 * (100 * 10 * 4),\n",
    "                  \"step_per_collect\": 20 * (10 * 4),\n",
    "                  \"episode_per_test\": 10,\n",
    "                  \"batch_size\" : 4 * 32,\n",
    "                  \"update_per_step\": 1 / 20, #Only run after close a Collect (run many times as necessary to meet the value)\n",
    "                  \"tn_eps_max\": 0.95,\n",
    "                  \"ts_eps_max\": 0.0,\n",
    "                  }\n",
    "\n",
    "def _get_env_eval():\n",
    "    \"\"\"This function is needed to provide callables for DummyVectorEnv.\"\"\"   \n",
    "    # env_paralell = MultiUAVEnv()  \n",
    "    env = pursuit_v4.env(\n",
    "        max_cycles=500,#max_cycles, \n",
    "        x_size=size[0], \n",
    "        y_size=size[1], \n",
    "        shared_reward=True, \n",
    "        n_evaders=n_targes,\n",
    "        n_pursuers=n_agents,\n",
    "        obs_range=obs_range, \n",
    "        n_catch=2, \n",
    "        freeze_evaders=False, \n",
    "        tag_reward=0.01,\n",
    "        catch_reward=5.0, \n",
    "        urgency_reward=-0.1, \n",
    "        surround=True, \n",
    "        constraint_window=1.0,\n",
    "        render_mode = \"human\" if render else None)\n",
    "    #env = parallel_to_aec_wrapper(env_paralell)    \n",
    "    #env = CustomParallelToAECWrapper(env_paralell)\n",
    "    \n",
    "    return PettingZooEnv(env)\n",
    "\n",
    "def _get_agents(\n",
    "    agent_learn: Optional[BasePolicy] = None,\n",
    "    agent_opponent: Optional[BasePolicy] = None,\n",
    "    optim: Optional[torch.optim.Optimizer] = None,\n",
    "    policy_load_path = None,\n",
    ") -> Tuple[BasePolicy, torch.optim.Optimizer, list]:\n",
    "    \n",
    "    env = _get_env_eval()     \n",
    "    env.seed(seed)  \n",
    "    agent_observation_space = env.observation_space\n",
    "   \n",
    "    action_shape = env.action_space\n",
    "    \n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"  \n",
    "\n",
    "    agents = []        \n",
    "    \n",
    "    if Policy_Config[\"same_policy\"]:\n",
    "        policies_number = 1\n",
    "    else:\n",
    "        policies_number = len(env.agents)\n",
    "\n",
    "    for _ in range(policies_number):      \n",
    "               \n",
    "        if model == \"CNN_SISL\":\n",
    "            net = CNN_SISL(\n",
    "                obs_shape=agent_observation_space.shape,                \n",
    "                action_shape=5,                \n",
    "                device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "                \n",
    "            ).to(device)            \n",
    "              \n",
    "        if Policy_Config[\"freeze_CNN\"]:                \n",
    "                net.freeze_conv_layers()  # Freeze the convolutional layers\n",
    "\n",
    "                optim = torch.optim.Adam(\n",
    "                    list(net.policy_fn.parameters()) + list(net.value_fn.parameters()), \n",
    "                    lr=dqn_params[\"lr\"]\n",
    "                )\n",
    "        else:\n",
    "            optim = torch.optim.Adam(net.parameters(), lr=dqn_params[\"lr\"], weight_decay=0.0, amsgrad= True )                \n",
    "\n",
    "\n",
    "\n",
    "        if policyModel == \"DQN\":\n",
    "            agent_learn = DQNPolicy(\n",
    "                model=net,\n",
    "                optim=optim,\n",
    "                action_space = action_shape,\n",
    "                discount_factor= dqn_params[\"discount_factor\"],\n",
    "                estimation_step=dqn_params[\"estimation_step\"],\n",
    "                target_update_freq=dqn_params[\"target_update_freq\"],\n",
    "                reward_normalization = False,\n",
    "                clip_loss_grad = False \n",
    "            ) \n",
    "         \n",
    "        \n",
    "        agents.append(agent_learn)\n",
    "\n",
    "    if Policy_Config[\"same_policy\"]:\n",
    "        agents = [agents[0] for _ in range(len(env.agents))]    \n",
    "\n",
    "    policy = MultiAgentPolicyManager(policies = agents, env=env)  \n",
    "        \n",
    "    return policy, optim, env.agents\n",
    "\n",
    "\n",
    "\n",
    "policy, optim, agents = _get_agents()\n",
    "     \n",
    "\n",
    "# Load the saved checkpoint\n",
    "for agent in agents:    \n",
    "    \n",
    "    if Policy_Config[\"same_policy\"]:\n",
    "        model_path = os.path.join(\"dqn_SISL\", name + \".pth\")                            \n",
    "    else:\n",
    "        model_path = os.path.join(\"dqn_SISL\", name + agent + \".pth\") \n",
    "\n",
    "    policy.policies[agent].set_eps(0.1)\n",
    "    policy.policies[agent].load_state_dict(torch.load(model_path))\n",
    "    # policy.policies[agent].eval()\n",
    "    \n",
    "\n",
    "envs = DummyVectorEnv([_get_env_eval for _ in range(1)])\n",
    "\n",
    "\n",
    "collector = CustomCollector(policy, envs, exploration_noise=False)\n",
    "\n",
    "results = collector.collect(n_episode=5, render=0.02 if render else None)#0.02)#, gym_reset_kwargs={'seed' :2})\n",
    "\n",
    "print(\"FinalRew: \", np.sum(results['rews'], axis = 1))\n",
    "print(\"Finished: \", results['lens'] , \" Steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.1528437500003\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n/ep': 5, 'n/st': 5392, 'rews': array([[ 61.55484375,  61.55484375,  61.55484375,  61.55484375,\n",
      "         61.55484375,  61.55484375,  61.55484375,  61.55484375],\n",
      "       [ 77.04296875,  77.04296875,  77.04296875,  77.04296875,\n",
      "         77.04296875,  77.04296875,  77.04296875,  77.04296875],\n",
      "       [ 50.95484375,  50.95484375,  50.95484375,  50.95484375,\n",
      "         50.95484375,  50.95484375,  50.95484375,  50.95484375],\n",
      "       [ 90.4775    ,  90.4775    ,  90.4775    ,  90.4775    ,\n",
      "         90.4775    ,  90.4775    ,  90.4775    ,  90.4775    ],\n",
      "       [105.7340625 , 105.7340625 , 105.7340625 , 105.7340625 ,\n",
      "        105.7340625 , 105.7340625 , 105.7340625 , 105.7340625 ]]), 'lens': array([1064,  920, 1376, 1200,  832]), 'idxs': array([0, 0, 0, 0, 0]), 'rew': 77.1528437500003, 'len': 1078.4, 'rew_std': 19.616714352468193, 'len_std': 194.60894121288467}\n"
     ]
    }
   ],
   "source": [
    "results['rews']\n",
    "print(np.mean(results['rews'][results['rews'] > -10]))\n",
    "\n",
    "\n",
    "#create a function  to print a histogram of the results['rews']\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(results['rews'][results['rews'] > -10], bins=100)\n",
    "plt.show()\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PettingZoo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
